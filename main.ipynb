{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7628f53-2ba9-4fa4-8908-3e542f2f229f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\anold\\anaconda3\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\anold\\anaconda3\\lib\\site-packages (from kagglehub) (23.2)\n",
      "Requirement already satisfied: requests in c:\\users\\anold\\anaconda3\\lib\\site-packages (from kagglehub) (2.32.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anold\\anaconda3\\lib\\site-packages (from kagglehub) (4.66.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anold\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anold\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anold\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anold\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\anold\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'mv' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#suur dataset, mdea kui hea kvaliteet, aga sitaks andmeid\n",
    "!pip install kagglehub\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"meruvulikith/190k-spam-ham-email-dataset-for-classification\")\n",
    "\n",
    "!mv {path} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38c8ea30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\anold\\anaconda3\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\anold\\anaconda3\\lib\\site-packages (from kagglehub) (23.2)\n",
      "Requirement already satisfied: requests in c:\\users\\anold\\anaconda3\\lib\\site-packages (from kagglehub) (2.32.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anold\\anaconda3\\lib\\site-packages (from kagglehub) (4.66.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anold\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anold\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anold\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anold\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\anold\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "['spam_Emails_data.csv']\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"meruvulikith/190k-spam-ham-email-dataset-for-classification\")\n",
    "import os\n",
    "print(os.listdir(path)) \n",
    "import pandas as np\n",
    "\n",
    "dpath = os.path.join(path, 'spam_Emails_data.csv')  \n",
    "SpamDataTest = pd.read_csv(dpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4da706d-3c69-4ca8-aa60-13ae808b6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import importlib\n",
    "SpamData1 = pd.read_csv(\"spam.csv\")\n",
    "SpamData2 = pd.read_csv(\"First_big_data.csv\")\n",
    "SpamData3=  pd.read_csv(\"Second_big_data.csv\")\n",
    "#SpamDataTest= pd.read_csv(\"spam_Emails_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5364936e-e5b5-4459-bd2b-780012351c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "SpamDataTest[\"label\"]=SpamDataTest[\"label\"].apply(lambda x: 0 if x==\"Ham\" else 1)\n",
    "SpamDataTest[\"text\"]=SpamDataTest[\"text\"].apply(lambda x:x if not isinstance(x, (int, float, complex)) and not isinstance(x, bool) else str(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4683ae3-54fc-4428-a0b9-7fc0dcefa469",
   "metadata": {},
   "outputs": [],
   "source": [
    "SpamData1[\"Category\"]=SpamData1[\"Category\"].apply(lambda x: 0 if x==\"ham\" else 1)\n",
    "SpamData1.rename(columns={'Category': 'label'}, inplace=True)\n",
    "SpamData1.rename(columns={'Message': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb001b20-b4ab-4187-b512-d1c569cc0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "SpamData= pd.concat([SpamData3, SpamData1, SpamData2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba86f19f-5f6a-45d3-8cf8-bedbab1abcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SpamDataModel= SpamData.copy()\n",
    "SpamDataModel2= SpamData.copy()\n",
    "SpamDataAnalyse = SpamData.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2fa6541",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1485\u001b[0m, in \u001b[0;36m_path_importer_cache\u001b[1;34m(cls, path)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'c:\\\\Users\\\\anold\\\\anaconda3\\\\Lib\\\\site-packages\\\\tensorflow\\\\python\\\\autograph\\\\pyct'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Uus\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mModel\u001b[39;00m\n\u001b[0;32m      3\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(Model)\n\u001b[0;32m      4\u001b[0m Neural\u001b[38;5;241m=\u001b[39mModel\u001b[38;5;241m.\u001b[39mNeural_Model(SpamDataModel)\n",
      "File \u001b[1;32mc:\\Users\\anold\\Documents\\SpamMail55\\Model.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout\n",
      "File \u001b[1;32mc:\\Users\\anold\\anaconda3\\Lib\\site-packages\\tensorflow\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32mc:\\Users\\anold\\anaconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "File \u001b[1;32mc:\\Users\\anold\\anaconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n",
      "File \u001b[1;32mc:\\Users\\anold\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m operators\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m asserts\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m break_statements\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m call_trees\n",
      "File \u001b[1;32mc:\\Users\\anold\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\converters\\asserts.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Converts assert statements to their corresponding TF calls.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgast\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m converter\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyct\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m templates\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAssertTransformer\u001b[39;00m(converter\u001b[38;5;241m.\u001b[39mBase):\n",
      "File \u001b[1;32mc:\\Users\\anold\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\core\\converter.py:64\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Converter construction support.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains a base class for all converters, as well as supporting\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03mdependency on AutoGraph.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01menum\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyct\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m anno\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyct\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ast_util\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyct\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parser\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1322\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1262\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1528\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1500\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1487\u001b[0m, in \u001b[0;36m_path_importer_cache\u001b[1;34m(cls, path)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1463\u001b[0m, in \u001b[0;36m_path_hooks\u001b[1;34m(path)\u001b[0m\n",
      "File \u001b[1;32m<frozen zipimport>:75\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, path)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Uus\n",
    "import Model\n",
    "importlib.reload(Model)\n",
    "Neural=Model.Neural_Model(SpamDataModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bc394b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.SaveModel(Neural,\"Neural\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14aa12d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model\n",
    "importlib.reload(Model)\n",
    "Neur=Model.ReadModel(\"Neural\")\n",
    "#Model.TestModel(Neural,SpamDataModel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c307780f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(Model)\n\u001b[1;32m----> 2\u001b[0m Model\u001b[38;5;241m.\u001b[39mTestModel(SpamDataModel2,Neur)\n",
      "File \u001b[1;32mc:\\Users\\anold\\Documents\\SpamMail55\\Model.py:122\u001b[0m, in \u001b[0;36mTestModel\u001b[1;34m(SpamDataTest, model)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mTestModel\u001b[39m(SpamDataTest, model):\n\u001b[0;32m    121\u001b[0m     SpamDataTest[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m SpamDataTest[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(word\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39msplit())) \u001b[38;5;66;03m#Removing the \\n and treating the words as 2 words\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(SpamDataTest[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    123\u001b[0m     y_test\u001b[38;5;241m=\u001b[39m SpamDataTest[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    124\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(Model)\n",
    "Model.TestModel(SpamDataModel2,Neur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8848fd93-8a85-4ab0-b1f9-6abd30b0065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model\n",
    "importlib.reload(Model)\n",
    "model=Model.RandomForestModel(SpamDataModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b891a3c-5d64-4975-99e6-54a7e8183d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label                                               text\n",
      "0           1  viiiiiiagraaaa only for the ones that want to ...\n",
      "1           1  got ice thought look az original message ice o...\n",
      "2           1  yo ur wom an ne eds an escapenumber in ch ma n...\n",
      "3           1  start increasing your odds of success & live s...\n",
      "4           1  author jra date escapenumber escapenumber esca...\n",
      "...       ...                                                ...\n",
      "193847      1  on escapenumber escapenumber escapenumber rob ...\n",
      "193848      1  we have everything you need escapelong cialesc...\n",
      "193849      1  hi quick question say i have a date variable i...\n",
      "193850      1  thank you for your loan request which we recie...\n",
      "193851      1  this is an automatically generated delivery st...\n",
      "\n",
      "[193852 rows x 2 columns]\n",
      "Accuracy: 71.86%\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(Model)\n",
    "print(SpamDataTest)\n",
    "Model.TestModel(model=model, SpamDataTest=SpamDataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "382970c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   96.67%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mModel\u001b[39;00m\n\u001b[0;32m      2\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(Model)\n\u001b[1;32m----> 3\u001b[0m SVM\u001b[38;5;241m=\u001b[39mModel\u001b[38;5;241m.\u001b[39mSVM_Model(SpamDataModel2)\n",
      "File \u001b[1;32mc:\\Users\\anold\\Documents\\SpamMail55\\Model.py:67\u001b[0m, in \u001b[0;36mSVM_Model\u001b[1;34m(SpamData)\u001b[0m\n\u001b[0;32m     65\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "import Model\n",
    "importlib.reload(Model)\n",
    "SVM=Model.SVM_Model(SpamDataModel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a085da",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(Model)\n",
    "Model.SaveModel(SVM,\"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31f4ba4c-27b8-4c56-a0f7-9d8e9839bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Analyse\n",
    "importlib.reload(Analyse)\n",
    "SpamDataAnalyse=  pd.concat([SpamDataTest, SpamDataAnalyse], ignore_index=True)\n",
    "SpamDataAnalyseCopy=SpamDataAnalyse.copy()\n",
    "SpamWordsDf, WordsDf = Analyse.FindWordCounts(SpamDataAnalyse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ede429c-37d0-4c5c-b66c-ad712efc7aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5179833988517775\n",
      "83863\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(SpamDataAnalyse[SpamDataAnalyse[\"label\"]==0][\"label\"])/len(SpamDataAnalyse[\"label\"]))\n",
    "print(SpamDataAnalyseCopy.duplicated().sum())\n",
    "print(len(SpamDataAnalyseCopy[SpamDataAnalyseCopy[\"label\"]==\" \"][\"label\"]))\n",
    "print(len(SpamDataAnalyseCopy[SpamDataAnalyseCopy[\"label\"]==\"\"][\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "76a0475d-fcf3-4eba-aee2-d91ccb1c6243",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m threshold_percentage\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m----> 2\u001b[0m tulemus \u001b[38;5;241m=\u001b[39m SpamWordsDf[\u001b[43mSpamWordsDf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mword\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mWordsDf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mword\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m~/PythonV/venv/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PythonV/venv/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PythonV/venv/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/PythonV/venv/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PythonV/venv/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[67], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      1\u001b[0m threshold_percentage\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m----> 2\u001b[0m tulemus \u001b[38;5;241m=\u001b[39m SpamWordsDf[SpamWordsDf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m word: word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m WordsDf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "threshold_percentage=0.1\n",
    "tulemus = SpamWordsDf[~SpamWordsDf['word'].isin(WordsDf['word'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ad111-d40c-49e0-be53-61f157efa879",
   "metadata": {},
   "outputs": [],
   "source": [
    "tulemus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9458ad55-8398-481d-9c45-7351b09183a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Words_Merged_df = pd.merge(SpamWordsDf, WordsDf, on='word', how='inner', suffixes=('_spam', '_notspam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19796a57-e979-4301-8581-ac61556c720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importlib.reload(Model)\n",
    "#Model.SaveModel(model, \"RandomForest(71.86)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cdf1ffbc-e397-48e2-bf1d-b3e85af6d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rf71=Model.ReadModel(\"RandomForest(71.86)\")\n",
    "wordCountSpam=sum(SpamWordsDf[\"count\"])\n",
    "wordCount=sum(WordsDf[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "28616fc2-0dd5-4ebd-a732-0298763d6696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48733382\n",
      "28568449\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Multiplier= wordCount/wordCountSpam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c10adf33-3967-4742-ae93-8c0be92150bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tulemusSpam=Words_Merged_df[Words_Merged_df[\"count_spam\"] > Words_Merged_df[\"count_notspam\"]*10*Multiplier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "03d9d95a-8fd8-491f-aaa8-5e45d87f2d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4139/2209070161.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tulemus2.sort_values(by='count_notspam', ascending=False, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "tulemusSpam.sort_values(by='count_notspam', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2de69710-eaff-43a7-af26-b215ef92977a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count_spam</th>\n",
       "      <th>count_notspam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cescapenumber</td>\n",
       "      <td>116167</td>\n",
       "      <td>4068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>aescapenumber</td>\n",
       "      <td>86593</td>\n",
       "      <td>3279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>eescapenumber</td>\n",
       "      <td>46980</td>\n",
       "      <td>2719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>|</td>\n",
       "      <td>36820</td>\n",
       "      <td>2119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>descapenumber</td>\n",
       "      <td>44528</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32051</th>\n",
       "      <td>prin</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32282</th>\n",
       "      <td>mmotley</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32419</th>\n",
       "      <td>girlie</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32490</th>\n",
       "      <td>cbis</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32531</th>\n",
       "      <td>cbi's</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1647 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  count_spam  count_notspam\n",
       "21     cescapenumber      116167           4068\n",
       "33     aescapenumber       86593           3279\n",
       "63     eescapenumber       46980           2719\n",
       "83                 |       36820           2119\n",
       "66     descapenumber       44528           1861\n",
       "...              ...         ...            ...\n",
       "32051           prin          18              1\n",
       "32282        mmotley          18              1\n",
       "32419         girlie          18              1\n",
       "32490           cbis          18              1\n",
       "32531          cbi's          18              1\n",
       "\n",
       "[1647 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tulemusSpam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ceddf35d-00be-45d3-bdd2-e8e3073d0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "TulemusNotSpam=Words_Merged_df[Words_Merged_df[\"count_spam\"]*10*Multiplier < Words_Merged_df[\"count_notspam\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9f8d3ea5-0263-4b5f-a8e8-3f9d2e8b9a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count_spam</th>\n",
       "      <th>count_notspam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>enron</td>\n",
       "      <td>9872</td>\n",
       "      <td>224707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>org</td>\n",
       "      <td>3066</td>\n",
       "      <td>89643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>&gt;</td>\n",
       "      <td>2078</td>\n",
       "      <td>69688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>pm</td>\n",
       "      <td>1899</td>\n",
       "      <td>66351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>guide</td>\n",
       "      <td>1791</td>\n",
       "      <td>38709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78860</th>\n",
       "      <td>My</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78861</th>\n",
       "      <td>4217</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78864</th>\n",
       "      <td>me?</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78881</th>\n",
       "      <td>wkend</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78883</th>\n",
       "      <td>texting</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4342 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  count_spam  count_notspam\n",
       "337      enron        9872         224707\n",
       "1143       org        3066          89643\n",
       "1590         >        2078          69688\n",
       "1711        pm        1899          66351\n",
       "1801     guide        1791          38709\n",
       "...        ...         ...            ...\n",
       "78860       My           1            100\n",
       "78861     4217           1             64\n",
       "78864      me?           1             19\n",
       "78881    wkend           1             33\n",
       "78883  texting           1             26\n",
       "\n",
       "[4342 rows x 3 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TulemusNotSpam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
